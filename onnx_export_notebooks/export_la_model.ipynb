{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Light Attention model\n",
    "\n",
    "There are two different sets of checkpoints for this model: one for the output dimension of 10 (called subcell) and one for the other output dimensions (in this case the only other used output dimension is 2)\n",
    "\n",
    "-> two onnx exports are necessary"
   ],
   "id": "bfef271619e2b817"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:56:05.691075Z",
     "start_time": "2025-03-21T16:56:03.145925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from prott5_batch_predictor import LA\n",
    "\n",
    "\n",
    "root_dir = Path.cwd().parent\n",
    "model_dir = root_dir / \"checkpoints\"\n",
    "\n",
    "la_model = LA(model_dir=model_dir, output_dim=2).model\n",
    "la_subcell_model = LA(model_dir=model_dir, output_dim=10).model"
   ],
   "id": "d3ce0c499f9fcf50",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:56:05.707876Z",
     "start_time": "2025-03-21T16:56:05.698653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path.cwd().parent\n",
    "model_dir = root_dir / \"checkpoints\"\n",
    "\n",
    "\n",
    "def export_LA_to_onnx(la_model, onnx_file_path=f'{root_dir}/checkpoints/light_attention_onnx', is_subcell_model=False):\n",
    "    if not os.path.exists(onnx_file_path):\n",
    "        os.mkdir(onnx_file_path)\n",
    "    # Define the dummy input tensor `x` and mask tensor `mask`\n",
    "    B = 2  # batch size\n",
    "    N = 5  # sequence length\n",
    "    C = 1024  # number of input channels/features\n",
    "\n",
    "    x = torch.randn(B, N, C)\n",
    "    x_transposed = torch.permute(x, (0,2,1))\n",
    "\n",
    "    mask = torch.ones(B, N)  # Mask tensor with shape (B, N). All ones means no masking\n",
    "\n",
    "    specific_onnx_file_path = f'{onnx_file_path}/la_subcell.onnx' if is_subcell_model else f'{onnx_file_path}/la.onnx'\n",
    "    # Export the model\n",
    "    torch.onnx.export(\n",
    "        la_model,                            # model being run\n",
    "        (x_transposed, mask),                # model input (or a tuple for multiple inputs)\n",
    "        specific_onnx_file_path,             # where to save the model\n",
    "        export_params=True,                  # store the trained parameter weights inside the model file\n",
    "        opset_version=12,                    # the ONNX version to export the model to\n",
    "        do_constant_folding=True,            # whether to execute constant folding for optimization\n",
    "        input_names=['input', 'mask'],       # the model's input names\n",
    "        output_names=['output'],             # the model's output names\n",
    "        dynamic_axes={'input': {0: 'batch_size', 1: 'sequence_length', 2: 'embedding_dim'},\n",
    "                      'mask': {0: 'batch_size', 1: 'sequence_length'},# variable length axes\n",
    "                      'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"Model has been successfully exported to {specific_onnx_file_path}\")"
   ],
   "id": "d13b0d9ed3cdb9a6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:56:07.185909Z",
     "start_time": "2025-03-21T16:56:05.992416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "export_LA_to_onnx(la_model=la_model)\n",
    "export_LA_to_onnx(la_model=la_subcell_model, is_subcell_model=True)"
   ],
   "id": "b85551a2dce4f36d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pschloetermann/IdeaProjects/Biocentral_ohne_original/pgp/prott5_batch_predictor.py:125: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  attention = attention.masked_fill(mask[:, None, :] == 0, torch.tensor(-1e+4))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been successfully exported to /Users/pschloetermann/IdeaProjects/Biocentral_ohne_original/pgp/checkpoints/light_attention_onnx/la.onnx\n",
      "Model has been successfully exported to /Users/pschloetermann/IdeaProjects/Biocentral_ohne_original/pgp/checkpoints/light_attention_onnx/la_subcell.onnx\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare results",
   "id": "34b50fc92f192237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T16:56:13.208405Z",
     "start_time": "2025-03-21T16:56:13.197758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "root_dir = Path.cwd().parent\n",
    "output_dir_org = f'{root_dir}/output_la_org'\n",
    "output_dir_onnx = f'{root_dir}/output_la_onnx'\n",
    "\n",
    "with open (f'{output_dir_onnx}/la_mem_pred.txt', 'r') as f:\n",
    "    la_mem_pred_onnx = f.read()\n",
    "\n",
    "with open (f'{output_dir_onnx}/la_subcell_pred.txt', 'r') as f:\n",
    "    la_subcell_pred_onnx = f.read()\n",
    "\n",
    "with open (f'{output_dir_org}/la_mem_pred.txt', 'r') as f:\n",
    "    la_mem_pred_org = f.read()\n",
    "\n",
    "with open (f'{output_dir_org}/la_subcell_pred.txt', 'r') as f:\n",
    "    la_subcell_pred_org = f.read()\n",
    "\n",
    "with open (f'{output_dir_org}/ids.txt', 'r') as f:\n",
    "    ids_org = f.read()\n",
    "\n",
    "with open (f'{output_dir_onnx}/ids.txt', 'r') as f:\n",
    "    ids_onnx = f.read()\n",
    "\n",
    "if ids_onnx == ids_org:\n",
    "    print(\"IDs of nnx conservation model and original conservation model output identical!\")\n",
    "if la_mem_pred_onnx == la_mem_pred_org:\n",
    "    print(\"LA membrane predictions are identical\")\n",
    "else:\n",
    "    print(\"LA membrane predictions are NOT identical\")\n",
    "if la_subcell_pred_onnx == la_subcell_pred_org:\n",
    "    print(\"LA subcell predictions are identical\")\n",
    "else:\n",
    "    print(\"LA subcell predictions are NOT identical\")"
   ],
   "id": "6a47cde53f5dbce5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs of nnx conservation model and original conservation model output identical!\n",
      "LA membrane predictions are identical\n",
      "LA subcell predictions are identical\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bbe0ae6df9322bfb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}

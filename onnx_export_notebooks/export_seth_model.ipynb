{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Export SETH model to onnx",
   "id": "315623440228d873"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-25T10:26:19.963873Z",
     "start_time": "2025-03-25T10:26:19.946654Z"
    }
   },
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from prott5_batch_predictor import SETH\n",
    "\n",
    "\n",
    "root_dir = Path.cwd().parent\n",
    "model_dir = root_dir / \"checkpoints\"\n",
    "\n",
    "seth_model = SETH(model_dir=model_dir).model\n",
    "\n",
    "import os\n",
    "\n",
    "def export_seth_to_onnx(seth_model, onnx_file_path=f'{root_dir}/checkpoints/seth_onnx'):\n",
    "    if not os.path.exists(onnx_file_path):\n",
    "        os.mkdir(onnx_file_path)\n",
    "\n",
    "    # Define the dummy input tensor `x` and mask tensor `mask`\n",
    "    B = 2  # batch size\n",
    "    N = 505  # sequence length\n",
    "    C = 1024  # number of input channels/features\n",
    "\n",
    "    x = torch.randn(B, N, C)\n",
    "\n",
    "    specific_onnx_file_path = f'{onnx_file_path}/seth.onnx'\n",
    "    # Export the model\n",
    "    torch.onnx.export(\n",
    "        seth_model,                               # model being run\n",
    "        x,                           # model input (or a tuple for multiple inputs)\n",
    "        specific_onnx_file_path,             # where to save the model\n",
    "        export_params=True,                  # store the trained parameter weights inside the model file\n",
    "        opset_version=12,                    # the ONNX version to export the model to\n",
    "        do_constant_folding=True,            # whether to execute constant folding for optimization\n",
    "        input_names=['input'],       # the model's input names\n",
    "        output_names=['output'],             # the model's output names\n",
    "        dynamic_axes={'input': {0: 'batch_size', 1: 'sequence_length', 2: 'embedding_dimension'},\n",
    "                      'output': {0: 'batch_size'}}\n",
    "    )\n",
    "    print(f\"Model has been successfully exported to {specific_onnx_file_path}\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T10:26:20.429445Z",
     "start_time": "2025-03-25T10:26:20.320300Z"
    }
   },
   "cell_type": "code",
   "source": "export_seth_to_onnx(seth_model=seth_model)",
   "id": "7d40f6557ac5b233",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been successfully exported to /Users/pschloetermann/IdeaProjects/Biocentral_ohne_original/pgp/checkpoints/seth_onnx/seth.onnx\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare results onnx <-> original model",
   "id": "988b5a61f1f5983c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:04:18.421510Z",
     "start_time": "2025-04-01T13:04:12.580592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def read_predictions(file_path):\n",
    "    predictions = []\n",
    "    with open(file_path, mode='r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            predictions.append(np.array([float(i) for i in row]))\n",
    "    return predictions"
   ],
   "id": "22e6c9b889fec385",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T13:09:24.994424Z",
     "start_time": "2025-04-01T13:09:24.982768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path.cwd().parent\n",
    "output_dir_org = f'{root_dir}/output_seth_org'\n",
    "output_dir_onnx = f'{root_dir}/output_seth_onnx'\n",
    "with open (f'{output_dir_onnx}/ids.txt', 'r') as f:\n",
    "    ids_onnx = f.read()\n",
    "with open (f'{output_dir_org}/ids.txt', 'r') as f:\n",
    "    ids_org = f.read()\n",
    "\n",
    "assert ids_onnx == ids_org, \"IDs of nnx tmbed model and original tmbed model output are NOT identical!\"\n",
    "\n",
    "seth_pred_org = read_predictions(f\"{output_dir_org}/seth_disorder_pred.csv\")\n",
    "seth_pred_onnx = read_predictions(f\"{output_dir_onnx}/seth_disorder_pred.csv\")\n",
    "for index, _ in enumerate(seth_pred_org):\n",
    "    np.testing.assert_allclose(seth_pred_org[index], seth_pred_onnx[index], rtol=1e-3, atol=1e-3)\n",
    "print(\"The predictions are numerically identical, maybe with negligible deviations in very small numerical ranges\")\n"
   ],
   "id": "5386b81343315346",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictions are numerically identical, maybe with negligible deviations in very small numerical ranges\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b8eaf249a147d9e6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
